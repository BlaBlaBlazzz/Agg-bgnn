hp:
  layers:
  - 1
  - 2
  d_token:
  - 96
  - 192
  - 288
  - 384
  lr:
  - 0.0003
  - 0.0001
  - 0.00003
  col_lr:
  - 0.0005
  - 0.001
  - 0.005
  attention_dropout:
  - 0.0
  - 0.3
  - 0.5


num_epochs: 100
patience: 20
